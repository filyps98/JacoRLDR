cuda:0
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=224, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=256, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
Starting position
[0.35 0.   0.  ]
end
[0.02  0.055 0.04 ]
Starting position
[0.35 0.   0.  ]
end
[0.02066969 0.05818225 0.04963381]
target
Episode:  0 | Episode Reward:  -0.5274080376671522
Starting position
[0.35 0.   0.  ]
end
[0.025 0.045 0.   ]
thumb_proximal
Episode:  1 | Episode Reward:  0.217446915709511
Starting position
[0.35 0.   0.  ]
end
[0.02979896 0.03685147 0.        ]
Episode:  2 | Episode Reward:  -1
Starting position
[0.35 0.   0.  ]
end
[0.02106823 0.04887488 0.        ]
Episode:  3 | Episode Reward:  0.19034209054743678
Starting position
[0.35 0.   0.  ]
end
[0.02645713 0.0619556  0.03892963]
thumb_proximal
Episode:  4 | Episode Reward:  -0.779795059823214
Starting position
[0.35 0.   0.  ]
end
[0.01587893 0.0514881  0.        ]
target
Episode:  5 | Episode Reward:  -0.920578874451531
Starting position
[0.35 0.   0.  ]
end
[0.01616965 0.05002887 0.04921261]
Episode:  6 | Episode Reward:  1.5365731201550306
Starting position
[0.35 0.   0.  ]
end
[0.02162423 0.04945955 0.        ]
target
thumb_proximal
Episode:  7 | Episode Reward:  -1
Starting position
[0.35 0.   0.  ]
end
[0.01633225 0.0416496  0.        ]
floor_foam_block
Episode:  8 | Episode Reward:  0.18194303411883506
Starting position
[0.35 0.   0.  ]
end
[0.01471438 0.05901546 0.04694902]
Episode:  9 | Episode Reward:  1.97586101115915
Starting position
[0.35 0.   0.  ]
end
[0.02664372 0.03974825 0.        ]
Episode:  10 | Episode Reward:  -0.9212094500685284
Starting position
[0.35 0.   0.  ]
end
[0.0211323  0.05208056 0.03778941]
target
Episode:  11 | Episode Reward:  -0.06860831850996418
Starting position
[0.35 0.   0.  ]
end
[0.03256191 0.04041872 0.        ]
thumb_proximal
Episode:  12 | Episode Reward:  -0.9099271102166264
Starting position
[0.35 0.   0.  ]
end
[0.02370401 0.04744177 0.04661023]
thumb_proximal
Episode:  13 | Episode Reward:  -0.5096528983931539
Starting position
[0.35 0.   0.  ]
end
[0.02626049 0.05885913 0.04385332]
target
thumb_proximal
Episode:  14 | Episode Reward:  1.2509717520950883
Starting position
[0.35 0.   0.  ]
end
[0.01750841 0.05974468 0.04258604]
target
thumb_proximal
Episode:  15 | Episode Reward:  3.067948023494581
Starting position
[0.35 0.   0.  ]
end
[0.02399722 0.05043482 0.0398498 ]
floor_foam_block
