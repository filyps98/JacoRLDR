
cuda:0
/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, "
/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_gen1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))
  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (linear1): Linear(in_features=4096, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=512, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (feature_extractor): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
  )
  (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_gen1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))
  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (linear1): Linear(in_features=4096, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
 height reward
0
Episode:  0 | Episode Reward:  0.5756219931381532
Episode:  1 | Episode Reward:  0.7131197564865362
Episode:  2 | Episode Reward:  0.32996933399296147
Episode:  3 | Episode Reward:  0.978141396507835
Episode:  4 | Episode Reward:  1.225425716597813
Episode:  5 | Episode Reward:  0.6053263634625418
Episode:  6 | Episode Reward:  1.3017947127831333
Episode:  7 | Episode Reward:  0.3538549100030134
 height reward
0
Episode:  8 | Episode Reward:  2.3202301414640933
Episode:  9 | Episode Reward:  1.3065395525392125
 height reward
0
Traceback (most recent call last):
  File "train.py", line 160, in <module>
    _=sac_trainer.update(batch_size, reward_scale=10., auto_entropy=AUTO_ENTROPY, target_entropy=-0.2*action_dim)
  File "/home/filippo/Desktop/Project/Experiments/JacoRLDR/sac/sac_trainer.py", line 66, in update
    feature_state =  self.feature_extractor(state_image)
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 460, in _conv_forward
    self.padding, self.dilation, self.groups)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 614.00 MiB (GPU 0; 1.96 GiB total capacity; 840.13 MiB already allocated; 470.44 MiB free; 860.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF