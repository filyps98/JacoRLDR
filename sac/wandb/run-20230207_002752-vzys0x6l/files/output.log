cuda:0
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=224, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=256, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
dimensions
12.936786057025374
8.012953867056755
Parameter
0.20203670582159203
reward distance
0.08462615338987353
dimensions
12.936786057025374
8.639675443406887
Parameter
0.20203670582159203
reward distance
0.09496472327576003
dimensions
12.936786057025374
5.199606712044433
Parameter
0.20203670582159203
reward distance
0.049760687867937546
dimensions
12.936786057025374
9.281131386400897
Parameter
0.20203670582159203
reward distance
0.10670290943390862
Episode:  0 | Episode Reward:  -0.7485716794223938
dimensions
14.736762387398525
7.230728959862958
Parameter
0.1773595563374966
reward distance
0.06194503303034931
dimensions
14.736762387398525
8.073122912004143
Parameter
0.1773595563374966
reward distance
0.07121627710297437
Episode:  1 | Episode Reward:  -0.9287837228970256
dimensions
16.4499804132007
8.041024803941392
Parameter
0.15888806996892688
reward distance
0.061665777140701185
Episode:  2 | Episode Reward:  -1
dimensions
13.668229903535588
6.0001021949341755
Parameter
0.19122488115333916
reward distance
0.05454546790459961
dimensions
13.668229903535588
6.1465720521848235
Parameter
0.19122488115333916
reward distance
0.05600803510842731
dimensions
13.668229903535588
5.369710225704967
Parameter
0.19122488115333916
reward distance
0.04865242620271572
dimensions
13.668229903535588
4.336117878940027
Parameter
0.19122488115333916
reward distance
0.040278458886962965
dimensions
13.668229903535588
4.555850074634187
Parameter
0.19122488115333916
reward distance
0.04193446621861609
dimensions
13.668229903535588
4.5050057767073275
Parameter
0.19122488115333916
reward distance
0.04154558256227116
Episode:  3 | Episode Reward:  0.22841896897899322
dimensions
16.938296847247024
7.276172970210482
Parameter
0.1543074644665301
reward distance
0.053290601461714084
dimensions
16.938296847247024
10.248575385423663
Parameter
0.1543074644665301
reward distance
0.08176768428789666
dimensions
16.938296847247024
13.376832034650835
Parameter
0.1543074644665301
reward distance
0.12610393894576433
dimensions
16.938296847247024
7.457202164051716
Parameter
0.1543074644665301
reward distance
0.05471761365895021
Episode:  4 | Episode Reward:  -0.7374107631073887
dimensions
16.464757726259414
6.6405483552558735
Parameter
0.15874546606364856
reward distance
0.0499333484538512
dimensions
16.464757726259414
11.241471428974693
Parameter
0.15874546606364856
reward distance
0.09837008674747544
Episode:  5 | Episode Reward:  -0.9016299132525245
dimensions
14.962362658968404
7.41906727047323
Parameter
0.17468535541166424
reward distance
0.06273787870637647
Episode:  6 | Episode Reward:  -1
dimensions
14.653743470764766
7.8747592409091345
Parameter
0.1783643643069522
reward distance
0.06943353273120631
dimensions
14.653743470764766
5.943815896778599
Parameter
0.1783643643069522
reward distance
0.05021913996929751
dimensions
14.653743470764766
10.797477864017635
Parameter
0.1783643643069522
reward distance
0.11163830735666924
dimensions
14.653743470764766
5.795314027724164
Parameter
0.1783643643069522
reward distance
0.04897070997495752
dimensions
14.653743470764766
3.75953930061658
Parameter
0.1783643643069522
reward distance
0.034575179541923524
dimensions
14.653743470764766
3.717391860811801
Parameter
0.1783643643069522
reward distance
0.03432512009635377
Episode:  7 | Episode Reward:  0.27972845693920156
dimensions
13.23291634627015
7.120349762032786
Parameter
0.19751546601568384
reward distance
