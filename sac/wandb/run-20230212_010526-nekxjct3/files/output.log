/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
cpu
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=224, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=256, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
Height Reward
-1.8636487522941114e-05
Height Reward
-1.7196378477926655e-05
Episode:  0 | Episode Reward:  -0.8462292566940287
Height Reward
-6.670041513973102e-05
Height Reward
-0.0005208806502982194
Height Reward
-2.2986898390531252e-05
Height Reward
-2.4416291115665623e-05
Episode:  1 | Episode Reward:  0.28570156653720824
Height Reward
-1.9226762485641258e-05
Episode:  2 | Episode Reward:  -1
Height Reward
-2.324331228909654e-05
Height Reward
-2.292850103852856e-05
Episode:  3 | Episode Reward:  -0.3881488962993177
Height Reward
-1.720658228558658e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-1.7196375793331053e-05
Episode:  4 | Episode Reward:  0.45895521918919097
Height Reward
-1.7399884035190077e-05
Episode:  5 | Episode Reward:  -1
Height Reward
-2.293011231453701e-05
Episode:  6 | Episode Reward:  -1
Height Reward
-1.7200835659536562e-05
Height Reward
-1.7196375801588337e-05
Height Reward
-1.7196375793331053e-05
Episode:  7 | Episode Reward:  -0.3542323169357364
Height Reward
0.009345150304747536
Height Reward
-2.2928501038542437e-05
Height Reward
-2.2928501038542437e-05
Height Reward
-2.2928501038542437e-05
Height Reward
-2.2928501038542437e-05
Height Reward
-0.00026450350164608505
Episode:  8 | Episode Reward:  0.9021333364757695
Height Reward
-0.00022802370592107934
Height Reward
-2.2928501038535498e-05
Episode:  9 | Episode Reward:  -0.39609528853686726
Height Reward
-1.719847107381489e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-1.7196375793331053e-05
Height Reward
-0.0007972964352510742
Height Reward
-0.00028932884503275746
Height Reward
9.688809105153073e-05
Episode:  10 | Episode Reward:  1.5383424322595882
Height Reward
0.023128274997405003
Height Reward
-2.2928475043919316e-05
Height Reward
0.0004205325490579323
Height Reward
0.00047776060674169923
Height Reward
-2.2928495332669163e-05
Height Reward
-2.2928501028141035e-05
Episode:  11 | Episode Reward:  1.6909244539140165
Height Reward
-0.00227409660663732
Height Reward
-1.719637585125694e-05
Episode:  12 | Episode Reward:  -0.8005617068289841
Height Reward
-1.7466513884338564e-05
Height Reward
-1.7196375793324115e-05
Height Reward
-1.7196375793324115e-05
Height Reward
-1.7196375793324115e-05
Height Reward
-1.7196375793324115e-05
Episode:  13 | Episode Reward:  0.10538094616759963
Height Reward
-2.293722208367155e-05
Height Reward
-2.2928501022236036e-05
Height Reward
-2.2928501038431415e-05
Height Reward
-2.2928501038431415e-05
Height Reward
-2.2928501038431415e-05
Height Reward
-2.2928501038431415e-05
Episode:  14 | Episode Reward:  0.519374390638998
Height Reward
-1.8809325991450687e-05
Height Reward
-1.7196375793337992e-05
Height Reward
-1.7196375793337992e-05
Height Reward
-1.7196375793337992e-05
Height Reward
