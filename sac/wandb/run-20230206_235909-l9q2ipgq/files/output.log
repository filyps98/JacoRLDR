cuda:0
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=224, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=256, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv1): Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))
  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pooling2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv_gen1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (linear1): Linear(in_features=256, out_features=480, bias=True)
  (linear_1): Linear(in_features=6, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
3
dimensions
[0.02145036 0.05252667 0.        ]
dimensions
0.052526672696597485
3
dimensions
[0.02145036 0.05252667 0.        ]
dimensions
0.052526672696597485
3
dimensions
[0.02145036 0.05252667 0.        ]
dimensions
0.052526672696597485
3
dimensions
[0.02145036 0.05252667 0.        ]
dimensions
0.052526672696597485
3
dimensions
[0.02145036 0.05252667 0.        ]
dimensions
0.052526672696597485
Episode:  0 | Episode Reward:  5.634185364465996
2
dimensions
[0.01960551 0.05608812 0.04810353]
dimensions
0.056088117108917666
2
dimensions
[0.01960551 0.05608812 0.04810353]
dimensions
0.056088117108917666
Episode:  1 | Episode Reward:  0.7726496003648209
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
3
dimensions
[0.01948945 0.05030108 0.        ]
dimensions
0.0503010800145635
Episode:  2 | Episode Reward:  9.461784584634348
2
dimensions
[0.01035466 0.06345386 0.04944073]
dimensions
0.06345385843635139
2
dimensions
[0.01035466 0.06345386 0.04944073]
dimensions
0.06345385843635139
2
dimensions
[0.01035466 0.06345386 0.04944073]
dimensions
0.06345385843635139
2
dimensions
[0.01035466 0.06345386 0.04944073]
dimensions
0.06345385843635139
Episode:  3 | Episode Reward:  4.460723089366414
3
dimensions
[0.02008697 0.03822469 0.        ]
dimensions
0.03822468674113811
3
dimensions
[0.02008697 0.03822469 0.        ]
dimensions
0.03822468674113811
3
dimensions
[0.02008697 0.03822469 0.        ]
dimensions
0.03822468674113811
3
dimensions
[0.02008697 0.03822469 0.        ]
dimensions
0.03822468674113811
3
dimensions
[0.02008697 0.03822469 0.        ]
dimensions
0.03822468674113811
Episode:  4 | Episode Reward:  7.712971361847902
2
dimensions
[0.02286042 0.04759278 0.0429708 ]
dimensions
0.047592779339387964
2
dimensions
[0.02286042 0.04759278 0.0429708 ]
dimensions
0.047592779339387964
Exception
Traceback (most recent call last):
  File "train.py", line 158, in <module>
    _=sac_trainer.update(batch_size, reward_scale=10., auto_entropy=AUTO_ENTROPY, target_entropy=-0.05*action_dim)
  File "/home/filippo/Desktop/Project/Experiments/JacoRLDR/sac/sac_trainer.py", line 109, in update
    self.policy_optimizer.zero_grad()
  File "/home/filippo/miniconda3/envs/robot/lib/python3.7/site-packages/torch/optim/optimizer.py", line 279, in zero_grad
    p.grad.zero_()
KeyboardInterrupt