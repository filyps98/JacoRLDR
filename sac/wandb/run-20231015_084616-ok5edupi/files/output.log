cuda:0
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Soft Q Network (1,2):  SoftQNetwork(
  (batch_norm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (batch_norm_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (conv_gen1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))
  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (linear1): Linear(in_features=4096, out_features=480, bias=True)
  (linear_bn_0_1): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear_bn_0_2): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear_bn_0_3): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear_bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear_bn_2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (final_linear_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear_1): Linear(in_features=10, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_state_combined): Linear(in_features=512, out_features=512, bias=True)
  (linear_combined_1): Linear(in_features=550, out_features=256, bias=True)
  (linear_combined_2): Linear(in_features=256, out_features=256, bias=True)
  (linear_combined_3): Linear(in_features=256, out_features=128, bias=True)
  (linear_action_1): Linear(in_features=7, out_features=64, bias=True)
  (linear_action_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_action_3): Linear(in_features=64, out_features=38, bias=True)
  (linear_final): Linear(in_features=128, out_features=1, bias=True)
)
Policy Network:  PolicyNetwork(
  (feature_extractor): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
  )
  (conv_gen1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))
  (conv_gen3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
  (conv_gen4): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))
  (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (linear1): Linear(in_features=4096, out_features=480, bias=True)
  (linear_1): Linear(in_features=10, out_features=64, bias=True)
  (linear_2): Linear(in_features=64, out_features=64, bias=True)
  (linear_3): Linear(in_features=64, out_features=32, bias=True)
  (linear_combined_1): Linear(in_features=512, out_features=1024, bias=True)
  (linear_combined_2): Linear(in_features=1024, out_features=1024, bias=True)
  (linear_combined_3): Linear(in_features=1024, out_features=512, bias=True)
  (mean_linear): Linear(in_features=512, out_features=7, bias=True)
  (log_std_linear): Linear(in_features=512, out_features=7, bias=True)
)
Episode:  0 | Episode Reward:  2.390685392800065
Episode:  1 | Episode Reward:  1.1637046224951908
Episode:  2 | Episode Reward:  1.4363751173947188
Episode:  3 | Episode Reward:  2.4879843994531794
Episode:  4 | Episode Reward:  0.7664614846000851
Episode:  5 | Episode Reward:  2.106667860316974
Episode:  6 | Episode Reward:  0.45267085212542263
Episode:  7 | Episode Reward:  1.4484963862629365
Episode:  8 | Episode Reward:  0.3809683602909879
Episode:  9 | Episode Reward:  2.4990330367402653
Episode:  10 | Episode Reward:  0.8272766142818319
Episode:  11 | Episode Reward:  4.947221084243583
Episode:  12 | Episode Reward:  1.4371893854670068
Exception
Episode:  13 | Episode Reward:  7.984263093829906
Episode:  14 | Episode Reward:  4.383277397714178
Episode:  15 | Episode Reward:  2.5342652705682376
Episode:  16 | Episode Reward:  7.3982124481336085
Episode:  17 | Episode Reward:  1.478880811607949
Episode:  18 | Episode Reward:  0.5674210638900358
Episode:  19 | Episode Reward:  0.6882327310503904
Traceback (most recent call last):
  File "train.py", line 190, in <module>
    sac_trainer.save_model(model_path)
  File "/root/home/JacoRLDR/sac/sac_trainer.py", line 156, in save_model
    torch.save(self.soft_q_net1.state_dict(), path+'_q1')
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 376, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/opt/conda/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './model/sac_v2_q1'